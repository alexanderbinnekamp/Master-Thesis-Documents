{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45d0e556",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim\n",
    "import nltk\n",
    "import re\n",
    "from sklearn.model_selection import KFold,cross_val_score,train_test_split,cross_val_predict\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "df = pd.read_excel('C:/Users/alexa/OneDrive/Documenten/Thesis Lab/dataset_final.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f609c211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Countrycode</th>\n",
       "      <th>Label</th>\n",
       "      <th>Sentence_translated</th>\n",
       "      <th>Sentence_original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>011_DEU_2020-03-27c_2022-05-20_10:59:17.4.txt</td>\n",
       "      <td>DEU</td>\n",
       "      <td>NONE</td>\n",
       "      <td>Law on the Establishment of an Economic Stabil...</td>\n",
       "      <td>'Gesetz zur Errichtung eines Wirtschaftsstabil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>011_DEU_2020-03-27c_2022-05-20_10:59:17.4.txt</td>\n",
       "      <td>DEU</td>\n",
       "      <td>NONE</td>\n",
       "      <td>I p. 543 (no.</td>\n",
       "      <td>'I S. 543 (Nr.',</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>011_DEU_2020-03-27c_2022-05-20_10:59:17.4.txt</td>\n",
       "      <td>DEU</td>\n",
       "      <td>NONE</td>\n",
       "      <td>14); Valid from March 28th, 2020 4 changes | P...</td>\n",
       "      <td>'14); Geltung ab 28.03.2020 4 Änderungen | Dr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>011_DEU_2020-03-27c_2022-05-20_10:59:17.4.txt</td>\n",
       "      <td>DEU</td>\n",
       "      <td>NONE</td>\n",
       "      <td>28th</td>\n",
       "      <td>'28.',</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>011_DEU_2020-03-27c_2022-05-20_10:59:17.4.txt</td>\n",
       "      <td>DEU</td>\n",
       "      <td>NONE</td>\n",
       "      <td>March 2020 StFG § 6- § 8- § 10- § 14e- § 15- §...</td>\n",
       "      <td>'März 2020 StFG § 6- § 8- § 10- § 14e- § 15- ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index                                       Filename Countrycode Label  \\\n",
       "0      0  011_DEU_2020-03-27c_2022-05-20_10:59:17.4.txt         DEU  NONE   \n",
       "1      1  011_DEU_2020-03-27c_2022-05-20_10:59:17.4.txt         DEU  NONE   \n",
       "2      2  011_DEU_2020-03-27c_2022-05-20_10:59:17.4.txt         DEU  NONE   \n",
       "3      3  011_DEU_2020-03-27c_2022-05-20_10:59:17.4.txt         DEU  NONE   \n",
       "4      4  011_DEU_2020-03-27c_2022-05-20_10:59:17.4.txt         DEU  NONE   \n",
       "\n",
       "                                 Sentence_translated  \\\n",
       "0  Law on the Establishment of an Economic Stabil...   \n",
       "1                                      I p. 543 (no.   \n",
       "2  14); Valid from March 28th, 2020 4 changes | P...   \n",
       "3                                               28th   \n",
       "4  March 2020 StFG § 6- § 8- § 10- § 14e- § 15- §...   \n",
       "\n",
       "                                   Sentence_original  \n",
       "0  'Gesetz zur Errichtung eines Wirtschaftsstabil...  \n",
       "1                                   'I S. 543 (Nr.',  \n",
       "2   '14); Geltung ab 28.03.2020 4 Änderungen | Dr...  \n",
       "3                                             '28.',  \n",
       "4   'März 2020 StFG § 6- § 8- § 10- § 14e- § 15- ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb1ed563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"let's test our function  by writing this string\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We'll write a function which will clean the text and prepare it.\n",
    "def cleanText(text):\n",
    "    cleaned = re.sub(\"[^a-zA-Z0-9']\",\" \",text)\n",
    "    lowered = cleaned.lower()\n",
    "    return lowered.strip()\n",
    "\n",
    "cleanText(\"Let's test our function, by writing this string!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a1de95f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"'gesetz zur errichtung eines wirtschaftsstabilisierungsfonds  wirtschaftsstabilisierungsfondsgesetz   wstfg  g  v  27 03 2020 bgbl '\",\n",
       " \"'i s  543  nr '\",\n",
       " \"'14   geltung ab 28 03 2020 4  nderungen   drucksachen   entwurf   begr ndung   wird in 8 vorschriften zitiert eingangsformel artikel 1  nderung des finanzmarktstabilisierungsfondsgesetzes artikel 2  nderung des finanzmarktstabilisierungsbeschleunigungsgesetzes artikel 3  nderung des kreditwesengesetzes artikel 4  nderung des wertpapierhandelsgesetzes artikel 5 inkrafttreten schlussformel  eingangsformel   der bundestag hat mit zustimmung des bundesrates das folgende gesetz beschlossen   inhaltsverzeichnis   ausdrucken pdf   nach oben  artikel 1  nderung des finanzmarktstabilisierungsfondsgesetzes  artikel 1 wird in 3 vorschriften zitiert und  ndert mwv '\",\n",
       " \"'28 '\"]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y = np.asarray(df[\"Sentence_original\"]),np.asarray(df[\"Label\"])\n",
    "\n",
    "x_cleaned = [cleanText(t) for t in x]\n",
    "x_cleaned[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68410a68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CONSUMER PROTECTION': 0,\n",
       " 'EMPLOYMENT POLICY': 1,\n",
       " 'FINANCIAL POLICY: DIRECT PAYMENTS': 2,\n",
       " 'FINANCIAL POLICY: GUARANTEES': 3,\n",
       " 'FINANCIAL POLICY: RESTRUCTURING OF LOAN TERMS': 4,\n",
       " 'FISCAL POLICY': 5,\n",
       " 'INDUSTRIAL POLICY': 6,\n",
       " 'NONE': 7,\n",
       " 'PRICE CONTROL': 8,\n",
       " 'SOCIAL WELFARE POLICY': 9}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Also we should convert our categories to the integer labels\n",
    "label_map = {cat:index for index,cat in enumerate(np.unique(y))}\n",
    "y_prep = np.asarray([label_map[l] for l in y])\n",
    "\n",
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38bf64c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"'gesetz\",\n",
       " 'zur',\n",
       " 'errichtung',\n",
       " 'eines',\n",
       " 'wirtschaftsstabilisierungsfonds',\n",
       " 'wirtschaftsstabilisierungsfondsgesetz',\n",
       " 'wstfg',\n",
       " 'g',\n",
       " 'v',\n",
       " '27',\n",
       " '03',\n",
       " '2020',\n",
       " 'bgbl',\n",
       " \"'\"]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tokenized = [[w for w in sentence.split(\" \") if w != \"\"] for sentence in x_cleaned]\n",
    "x_tokenized[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfe45eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'gesetz\n",
      "zur\n",
      "errichtung\n",
      "eines\n",
      "wirtschaftsstabilisierungsfonds\n",
      "wirtschaftsstabilisierungsfondsgesetz\n",
      "wstfg\n",
      "g\n",
      "v\n",
      "27\n",
      "03\n",
      "2020\n",
      "bgbl\n",
      "'\n"
     ]
    }
   ],
   "source": [
    "for i in x_tokenized[0]:\n",
    "    print(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b07eaf82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This process took 57.88 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Now we'll create our model \n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "model = gensim.models.FastText(x_tokenized,\n",
    "                 vector_size=600, sg=0, ns_exponent=1\n",
    "                 # Size is the length of our vector.\n",
    "                )\n",
    "\n",
    "end = round(time.time()-start,2)\n",
    "print(\"This process took\",end,\"seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc2ad030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ser', 0.9837781190872192),\n",
       " ('iscrivere', 0.982687771320343),\n",
       " ('svolgere', 0.9824087023735046),\n",
       " ('subi', 0.9770069122314453),\n",
       " ('percevoir', 0.9752346277236938),\n",
       " ('sul', 0.9749611616134644),\n",
       " ('sud', 0.9737043976783752),\n",
       " ('sua', 0.973050057888031),\n",
       " ('dazu', 0.9716665148735046),\n",
       " ('tercer', 0.9714767932891846)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"free\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22a81dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequencer():\n",
    "    \n",
    "    def __init__(self,\n",
    "                 all_words,\n",
    "                 max_words,\n",
    "                 seq_len,\n",
    "                 embedding_matrix\n",
    "                ):\n",
    "        \n",
    "        self.seq_len = seq_len\n",
    "        self.embed_matrix = embedding_matrix\n",
    "        \"\"\"\n",
    "        temp_vocab = Vocab which has all the unique words\n",
    "        self.vocab = Our last vocab which has only most used N words.\n",
    "    \n",
    "        \"\"\"\n",
    "        temp_vocab = list(set(all_words))\n",
    "        self.vocab = []\n",
    "        self.word_cnts = {}\n",
    "        \"\"\"\n",
    "        Now we'll create a hash map (dict) which includes words and their occurencies\n",
    "        \"\"\"\n",
    "        for word in temp_vocab:\n",
    "            # 0 does not have a meaning, you can add the word to the list\n",
    "            # or something different.\n",
    "            count = len([0 for w in all_words if w == word])\n",
    "            self.word_cnts[word] = count\n",
    "            counts = list(self.word_cnts.values())\n",
    "            indexes = list(range(len(counts)))\n",
    "        \n",
    "        # Now we'll sort counts and while sorting them also will sort indexes.\n",
    "        # We'll use those indexes to find most used N word.\n",
    "        cnt = 0\n",
    "        while cnt + 1 != len(counts):\n",
    "            cnt = 0\n",
    "            for i in range(len(counts)-1):\n",
    "                if counts[i] < counts[i+1]:\n",
    "                    counts[i+1],counts[i] = counts[i],counts[i+1]\n",
    "                    indexes[i],indexes[i+1] = indexes[i+1],indexes[i]\n",
    "                else:\n",
    "                    cnt += 1\n",
    "        \n",
    "        for ind in indexes[:max_words]:\n",
    "            self.vocab.append(temp_vocab[ind])\n",
    "                    \n",
    "    def textToVector(self,text):\n",
    "        # First we need to split the text into its tokens and learn the length\n",
    "        # If length is shorter than the max len we'll add some spaces (100D vectors which has only zero values)\n",
    "        # If it's longer than the max len we'll trim from the end.\n",
    "        tokens = text.split()\n",
    "        len_v = len(tokens)-1 if len(tokens) < self.seq_len else self.seq_len-1\n",
    "        vec = []\n",
    "        for tok in tokens[:len_v]:\n",
    "            try:\n",
    "                vec.append(self.embed_matrix[tok])\n",
    "            except Exception as E:\n",
    "                pass\n",
    "        \n",
    "        last_pieces = self.seq_len - len(vec)\n",
    "        for i in range(last_pieces):\n",
    "            vec.append(np.zeros(600,))\n",
    "        \n",
    "        return np.asarray(vec).flatten()\n",
    "                \n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b77f62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequencer = Sequencer(all_words = [token for seq in x_tokenized for token in seq],\n",
    "              max_words = 1500,\n",
    "              seq_len = 15,\n",
    "              embedding_matrix = model.wv\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf842a7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00224058,  0.02579685, -0.13051185, ...,  0.        ,\n",
       "        0.        ,  0.        ])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_vec = sequencer.textToVector(\"i am in love with you\")\n",
    "test_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30e20dee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "990eb71f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9000,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8467d239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5450, 9000)\n"
     ]
    }
   ],
   "source": [
    "# But before creating a PCA model using scikit-learn let's create\n",
    "# vectors for our each vector\n",
    "x_vecs = np.asarray([sequencer.textToVector(\" \".join(seq)) for seq in x_tokenized])\n",
    "print(x_vecs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3952fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of variance ratios:  0.9999986645912589\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca_model = PCA(n_components=1090)\n",
    "pca_model.fit(x_vecs)\n",
    "print(\"Sum of variance ratios: \",sum(pca_model.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24388a86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5450, 1090)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_comps = pca_model.transform(x_vecs)\n",
    "x_comps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc030e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4360, 1090)\n",
      "(1090, 1090)\n",
      "(4360,)\n",
      "(1090,)\n"
     ]
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x_comps,y_prep,test_size=0.2,random_state=42)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "960e4b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine Classifier has fitted, this process took 85.33 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time() \n",
    "\n",
    "svm_classifier = LinearSVC(dual=False)\n",
    "svm_classifier.fit(x_train,y_train)\n",
    "\n",
    "end = time.time()\n",
    "process = round(end-start,2)\n",
    "print(\"Support Vector Machine Classifier has fitted, this process took {} seconds\".format(process))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17b60e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = svm_classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3cfde8aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7412844036697248"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_classifier.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2cf6b8c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTION ON TEST\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         9\n",
      "           1       0.40      0.11      0.17        57\n",
      "           2       0.45      0.17      0.25        81\n",
      "           3       0.25      0.02      0.04        48\n",
      "           4       0.00      0.00      0.00        20\n",
      "           5       0.33      0.03      0.06        31\n",
      "           6       0.00      0.00      0.00         4\n",
      "           7       0.77      0.97      0.85       813\n",
      "           8       0.00      0.00      0.00         6\n",
      "           9       0.20      0.05      0.08        21\n",
      "\n",
      "    accuracy                           0.74      1090\n",
      "   macro avg       0.24      0.13      0.14      1090\n",
      "weighted avg       0.65      0.74      0.67      1090\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"PREDICTION ON TEST\")\n",
    "print(classification_report(y_test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9219edc0",
   "metadata": {},
   "source": [
    "Note: precision is higher than recall, meaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d57a9600",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold,cross_val_score,train_test_split,cross_val_predict\n",
    "\n",
    "from sklearn import metrics\n",
    "scores = cross_val_score(svm_classifier, x_train, y_train, cv=10, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "673d9b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.76146789 0.75       0.73623853 0.7293578  0.74311927 0.74541284\n",
      " 0.75688073 0.75917431 0.76605505 0.75229358]\n"
     ]
    }
   ],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8cb6f6a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "average = statistics.mean(scores)\n",
    "print(average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05f54e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c7232d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7841ec72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
